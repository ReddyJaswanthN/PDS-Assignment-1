# -*- coding: utf-8 -*-
"""Untitled16.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Jj1rYHwnXlRXLlvY7gp_-aVcVLfclxxT
"""

import pandas as pd
import os

# Define file paths
raw_data_path = "/content/StudentsPerformance.csv"  # Path to the uploaded file
cleaned_data_path = "/content/cleaned_student_performance.csv"  # Path to save the cleaned file

# Check if the raw data file exists
if not os.path.exists(raw_data_path):
    raise FileNotFoundError("Raw data file not found. Please upload 'StudentsPerformance.csv' to the Colab environment.")

# Read the CSV file
df = pd.read_csv(raw_data_path)

# Clean column names (convert to lowercase and replace spaces with underscores)
df.columns = df.columns.str.lower().str.replace(' ', '_')

# Check for missing values
missing_values = df.isnull().sum()
print("Missing values in each column:")
print(missing_values)

# Remove rows with missing values (if any)
df = df.dropna()

# Convert categorical variables to categorical type
categorical_vars = ["gender", "race/ethnicity", "parental_level_of_education", "lunch", "test_preparation_course"]
df[categorical_vars] = df[categorical_vars].astype('category')

# Create average score column
df['average_score'] = (df['math_score'] + df['reading_score'] + df['writing_score']) / 3

# Create performance category
bins = [0, 40, 60, 75, 100]
labels = ["Poor", "Average", "Good", "Excellent"]
df['performance_category'] = pd.cut(df['average_score'], bins=bins, labels=labels)

# Check data types
print("Data types of each column:")
print(df.dtypes)

# Summary statistics
summary_stats = df.describe(include='all')
print("Summary statistics:")
print(summary_stats)

# Save the cleaned data
df.to_csv(cleaned_data_path, index=False)

print(f"Cleaned data saved to: {cleaned_data_path}")

import pandas as pd
import numpy as np
import os
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.feature_selection import VarianceThreshold
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split

# Define file paths
cleaned_data_path = "/content/cleaned_student_performance.csv"  # Update this path
preprocessed_data_path = "/content/preprocessed_student_performance.csv"  # Update this path
visualization_path = "/content/results"  # Directory to save visualizations

# Check if the cleaned data file exists
if not os.path.exists(cleaned_data_path):
    raise FileNotFoundError("Cleaned data file not found. Please ensure the cleaned_student_performance.csv file is in the correct directory.")

# Read the cleaned CSV file
df = pd.read_csv(cleaned_data_path)

# 1. Feature Engineering

# Create a binary column for passing (average score >= 60)
df['passed'] = df['average_score'].apply(lambda x: 1 if x >= 60 else 0)

# Create interaction terms
df['prep_parent_edu'] = df['test_preparation_course'] + "_" + df['parental_level_of_education']
df['prep_lunch'] = df['test_preparation_course'] + "_" + df['lunch']

# 2. Encoding categorical variables
# One-hot encoding for multi-level categorical variables
categorical_vars = ["gender", "race/ethnicity", "parental_level_of_education", "lunch", "test_preparation_course", "prep_parent_edu", "prep_lunch"]
df_encoded = pd.get_dummies(df, columns=categorical_vars, drop_first=True)

# 3. Scaling numerical features
numeric_features = ["math_score", "reading_score", "writing_score", "average_score"]
scaler = StandardScaler()
df_encoded[numeric_features] = scaler.fit_transform(df_encoded[numeric_features])

# 4. Feature selection (example: removing highly correlated features)
# Select only numeric columns for correlation calculation
numeric_df = df_encoded.select_dtypes(include=[np.number])
correlation_matrix = numeric_df.corr().abs()

# Identify highly correlated features
upper_tri = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))
highly_correlated = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]

# Drop highly correlated features
df_encoded = df_encoded.drop(columns=highly_correlated)

# 5. Add a unique identifier
df_encoded['student_id'] = range(1, len(df_encoded) + 1)

# 6. Reorder columns (student_id first)
df_encoded = df_encoded[['student_id'] + [col for col in df_encoded.columns if col != 'student_id']]

# Create the processed_data directory if it doesn't exist
os.makedirs(os.path.dirname(preprocessed_data_path), exist_ok=True)

# Save the preprocessed data
df_encoded.to_csv(preprocessed_data_path, index=False)

print(f"Preprocessed data saved to: {preprocessed_data_path}")

# Print summary of preprocessed data
print("Summary of preprocessed data:")
print(df_encoded.describe())

# Print dimensions of preprocessed data
print(f"Dimensions of preprocessed data: {df_encoded.shape[0]} rows and {df_encoded.shape[1]} columns")

# Visualizations
os.makedirs(visualization_path, exist_ok=True)

# 1. Distribution of average scores
plt.figure(figsize=(10, 6))
sns.histplot(df['average_score'], kde=True, color='skyblue', bins=30)
plt.title("Distribution of Average Scores")
plt.xlabel("Average Score")
plt.ylabel("Density")
plt.savefig(os.path.join(visualization_path, "avg_score_distribution.png"))
plt.show()

# 2. Performance category by gender
plt.figure(figsize=(10, 6))
sns.countplot(data=df, x='performance_category', hue='gender', palette='Set2')
plt.title("Performance Category by Gender")
plt.xlabel("Performance Category")
plt.ylabel("Count")
plt.xticks(rotation=45)
plt.savefig(os.path.join(visualization_path, "performance_by_gender.png"))
plt.show()

# 3. Correlation heatmap of scores
score_cols = ["math_score", "reading_score", "writing_score", "average_score"]
cor_matrix = df[score_cols].corr()
plt.figure(figsize=(7, 6))
sns.heatmap(
    cor_matrix,
    annot=True,
    cmap='RdYlBu',  # Custom colormap
    fmt='.2f',
    annot_kws={'size': 12},  # Larger annotation font size
    linewidths=0.5  # Line width between cells
)
plt.title("Correlation Heatmap of Scores")
plt.savefig(os.path.join(visualization_path, "score_correlation_heatmap.png"))
plt.show()


# 4. Average scores by parental education level
plt.figure(figsize=(12, 6))
sns.boxplot(data=df, x='parental_level_of_education', y='average_score', palette='Set3')
plt.title("Average Scores by Parental Education Level")
plt.xlabel("Parental Education Level")
plt.ylabel("Average Score")
plt.xticks(rotation=45)
plt.savefig(os.path.join(visualization_path, "avg_score_by_parent_education.png"))
plt.show()

# 5. Average scores by test preparation course
plt.figure(figsize=(10, 6))
sns.violinplot(data=df, x='test_preparation_course', y='average_score', palette='Set2')
plt.title("Average Scores by Test Preparation Course")
plt.xlabel("Test Preparation Course")
plt.ylabel("Average Score")
plt.savefig(os.path.join(visualization_path, "avg_score_by_test_prep.png"))
plt.show()

print("Visualizations completed and saved in the results folder.")