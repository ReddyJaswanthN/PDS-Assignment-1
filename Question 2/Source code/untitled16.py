# -*- coding: utf-8 -*-
"""Untitled16.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Jj1rYHwnXlRXLlvY7gp_-aVcVLfclxxT
"""

import pandas as pd
import os


raw_data_path = "/content/StudentsPerformance.csv"  
cleaned_data_path = "/content/cleaned_student_performance.csv"  


if not os.path.exists(raw_data_path):
    raise FileNotFoundError("Raw data file not found. Please upload 'StudentsPerformance.csv' to the Colab environment.")


df = pd.read_csv(raw_data_path)

df.columns = df.columns.str.lower().str.replace(' ', '_')


missing_values = df.isnull().sum()
print("Missing values in each column:")
print(missing_values)


df = df.dropna()


categorical_vars = ["gender", "race/ethnicity", "parental_level_of_education", "lunch", "test_preparation_course"]
df[categorical_vars] = df[categorical_vars].astype('category')

df['average_score'] = (df['math_score'] + df['reading_score'] + df['writing_score']) / 3


bins = [0, 40, 60, 75, 100]
labels = ["Poor", "Average", "Good", "Excellent"]
df['performance_category'] = pd.cut(df['average_score'], bins=bins, labels=labels)


print("Data types of each column:")
print(df.dtypes)


summary_stats = df.describe(include='all')
print("Summary statistics:")
print(summary_stats)


df.to_csv(cleaned_data_path, index=False)

print(f"Cleaned data saved to: {cleaned_data_path}")

import pandas as pd
import numpy as np
import os
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.feature_selection import VarianceThreshold
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split

cleaned_data_path = "/content/cleaned_student_performance.csv"  
preprocessed_data_path = "/content/preprocessed_student_performance.csv"  
visualization_path = "/content/results"  

if not os.path.exists(cleaned_data_path):
    raise FileNotFoundError("Cleaned data file not found. Please ensure the cleaned_student_performance.csv file is in the correct directory.")


df = pd.read_csv(cleaned_data_path)




df['passed'] = df['average_score'].apply(lambda x: 1 if x >= 60 else 0)


df['prep_parent_edu'] = df['test_preparation_course'] + "_" + df['parental_level_of_education']
df['prep_lunch'] = df['test_preparation_course'] + "_" + df['lunch']



categorical_vars = ["gender", "race/ethnicity", "parental_level_of_education", "lunch", "test_preparation_course", "prep_parent_edu", "prep_lunch"]
df_encoded = pd.get_dummies(df, columns=categorical_vars, drop_first=True)


numeric_features = ["math_score", "reading_score", "writing_score", "average_score"]
scaler = StandardScaler()
df_encoded[numeric_features] = scaler.fit_transform(df_encoded[numeric_features])



numeric_df = df_encoded.select_dtypes(include=[np.number])
correlation_matrix = numeric_df.corr().abs()


upper_tri = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))
highly_correlated = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]


df_encoded = df_encoded.drop(columns=highly_correlated)


df_encoded['student_id'] = range(1, len(df_encoded) + 1)


df_encoded = df_encoded[['student_id'] + [col for col in df_encoded.columns if col != 'student_id']]


os.makedirs(os.path.dirname(preprocessed_data_path), exist_ok=True)


df_encoded.to_csv(preprocessed_data_path, index=False)

print(f"Preprocessed data saved to: {preprocessed_data_path}")

print("Summary of preprocessed data:")
print(df_encoded.describe())


print(f"Dimensions of preprocessed data: {df_encoded.shape[0]} rows and {df_encoded.shape[1]} columns")


os.makedirs(visualization_path, exist_ok=True)

# 1. Distribution of average scores
plt.figure(figsize=(10, 6))
sns.histplot(df['average_score'], kde=True, color='skyblue', bins=30)
plt.title("Distribution of Average Scores")
plt.xlabel("Average Score")
plt.ylabel("Density")
plt.savefig(os.path.join(visualization_path, "avg_score_distribution.png"))
plt.show()

# 2. Performance category by gender
plt.figure(figsize=(10, 6))
sns.countplot(data=df, x='performance_category', hue='gender', palette='Set2')
plt.title("Performance Category by Gender")
plt.xlabel("Performance Category")
plt.ylabel("Count")
plt.xticks(rotation=45)
plt.savefig(os.path.join(visualization_path, "performance_by_gender.png"))
plt.show()

# 3. Correlation heatmap of scores
score_cols = ["math_score", "reading_score", "writing_score", "average_score"]
cor_matrix = df[score_cols].corr()
plt.figure(figsize=(7, 6))
sns.heatmap(
    cor_matrix,
    annot=True,
    cmap='RdYlBu',  
    fmt='.2f',
    annot_kws={'size': 12},  
    linewidths=0.5  
)
plt.title("Correlation Heatmap of Scores")
plt.savefig(os.path.join(visualization_path, "score_correlation_heatmap.png"))
plt.show()


# 4. Average scores by parental education level
plt.figure(figsize=(12, 6))
sns.boxplot(data=df, x='parental_level_of_education', y='average_score', palette='Set3')
plt.title("Average Scores by Parental Education Level")
plt.xlabel("Parental Education Level")
plt.ylabel("Average Score")
plt.xticks(rotation=45)
plt.savefig(os.path.join(visualization_path, "avg_score_by_parent_education.png"))
plt.show()

# 5. Average scores by test preparation course
plt.figure(figsize=(10, 6))
sns.violinplot(data=df, x='test_preparation_course', y='average_score', palette='Set2')
plt.title("Average Scores by Test Preparation Course")
plt.xlabel("Test Preparation Course")
plt.ylabel("Average Score")
plt.savefig(os.path.join(visualization_path, "avg_score_by_test_prep.png"))
plt.show()

print("Visualizations completed and saved in the results folder.")